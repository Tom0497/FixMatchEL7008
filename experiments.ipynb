{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "0368c914-1121-4017-a1b5-b26ba8db2593",
     "kernelId": ""
    },
    "id": "itOacuX_2NO2"
   },
   "source": [
    "# Proyecto EL7008 | Primavera 2021\n",
    "## Aprendizaje semi-supervisado basado en FixMatch\n",
    "#### Paper original por Kihyuk Sohn y David Berthelot en [arXiv](https://arxiv.org/abs/2001.07685)\n",
    "\n",
    "---\n",
    "**Autor:** ***Tomás Rodrigo Saldivia Astudillo***  \n",
    "\n",
    "---\n",
    "\n",
    "En este proyecto se busca elaborar un clasificador de imágenes siguiendo el paradigma de aprendizaje semi-supervisado (SSL), en particular utilizando el algoritmo FixMatch. El aprendizaje semi-supervisado consiste en combinar una pequeña cantidad de datos etiquetados con una gran cantidad de datos no-etiquetados para entrenar un modelo, y FixMatch en particular lo hace generando una pseudo-label para datos no-etiquetados mediante consistency regularization.  \n",
    "\n",
    "En el proyecto se implementa este algoritmo y se aplica en CIFAR-10 y\n",
    "CIFAR-100. Se prueban dos arquitecturas distintas, ambas variantes de WideResNet y se utilizan dos esquemas de data augmentation fuertes distintos para comparar con sus resultados, siendo uno de estos RandAugment.  \n",
    "\n",
    "Se analiza y cuantifica el efecto que tienen los datos no-etiquetados en el entrenamiento en cada caso, y además se compara con el caso sin FixMatch. El proyecto esta desarrollado en python utilizando Pytorch.\n",
    "\n",
    "***RandAugment***: [paper en arXiv](https://arxiv.org/abs/1909.13719)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cabff1f1-a31e-48c6-985f-ff887bc624f6",
     "kernelId": ""
    },
    "id": "91G7p8Ut4wJz"
   },
   "source": [
    "## Código\n",
    "\n",
    "El código implementado se encuentra en el repositorio [github:Tom0497/FixMatchEL7008](https://github.com/Tom0497/FixMatchEL7008) y cuenta con scripts para ejecutar los distintos tipos de entrenamientos asociados a los experimentos que se desean realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "0c261d22-55f5-4f70-8440-13c8c13df167",
     "kernelId": ""
    },
    "id": "iaMPOJiVInTn"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Tom0497/FixMatchEL7008.git\n",
    "%cd FixMatchEL7008/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "978cdd9b-382d-40c6-a02f-b543966a414b",
     "kernelId": ""
    },
    "id": "gu_Tu8255KuV"
   },
   "source": [
    "Es imperativo agregar el directorio raíz del proyecto a la variable de entorno de python, de esta manera, las exportaciones de los distintos modulos funcionaran de la manera correcta. Se puede tomar la siguiente celda, que imprime el current working directory, y luego modificar la variable de entorno PYTHONPATH para que la contenga. La celda de más abajo funciona en PaperSpace, pero en colab se debiera cambiar `os.environ['PYTHONPATH'] =` por `os.environ['PYTHONPATH'] +=`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "39f5379c-b0a5-41cd-93ba-2c83e6284677",
     "kernelId": ""
    },
    "id": "SkAYvMOXYu_6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "2ced21fd-445c-4dc3-8907-e30493e58ecc",
     "kernelId": ""
    },
    "id": "Y66VOkHQKHmm"
   },
   "outputs": [],
   "source": [
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "590cf615-03db-4ab2-adba-0b038b70b8da",
     "kernelId": ""
    },
    "id": "J9zbnvwrI-4E"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYTHONPATH'] = \"/notebooks/FixMatchEL7008:\"\n",
    "!echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Requerimientos\n",
    "\n",
    "Para la correcta ejecución del código se requiere de pytorch en su última versión, en específico torchvision 0.11.2 o más. Además, se utiliza sklearn, matplotlib, numpy."
   ],
   "metadata": {
    "id": "NND351kJY2QF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkjWtV6lYu_9"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "dfd316e7-63da-4bac-9232-950cd8970643",
     "kernelId": ""
    },
    "id": "OExTxB1m5ZlV"
   },
   "source": [
    "### Entrenamiento supervisado sobre CIFAR\n",
    "\n",
    "El script `supervised.py` permite la ejecución de un entrenamiento totalmente supervisado sobre CIFAR10 o CIFAR100. Gran parte de los hiper parámetros de entrenamiento son ajustables, como también lo es la arquitectura del modelo WideResNet utilizar. Se muestran a continuación las opciones disponibles para ejecutar el script.\n",
    "\n",
    "```{bash}\n",
    "usage: supervised.py [-h] [-d {cifar10,cifar100}] [-e EPOCHS] [-bs BATCH_SIZE]\n",
    "                     [-md MODEL_DEPTH] [-mw MODEL_WIDTH] [-es EARLY_STOPPING]\n",
    "                     [-r RESULTS] [-tr TRAIN_RANGE TRAIN_RANGE]\n",
    "                     [-vr VAL_RANGE VAL_RANGE]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -d {cifar10,cifar100}, --data {cifar10,cifar100}\n",
    "                        dataset for training\n",
    "  -e EPOCHS, --epochs EPOCHS\n",
    "                        number of epochs for training\n",
    "  -bs BATCH_SIZE, --batch-size BATCH_SIZE\n",
    "                        batch size for training\n",
    "  -md MODEL_DEPTH, --model-depth MODEL_DEPTH\n",
    "                        depth of Wide ResNet model\n",
    "  -mw MODEL_WIDTH, --model-width MODEL_WIDTH\n",
    "                        width of Wide ResNet model\n",
    "  -es EARLY_STOPPING, --early-stopping EARLY_STOPPING\n",
    "                        number of epochs for early stopping\n",
    "  -r RESULTS, --results RESULTS\n",
    "                        folder name for training results\n",
    "  -tr TRAIN_RANGE TRAIN_RANGE, --train-range TRAIN_RANGE TRAIN_RANGE\n",
    "                        range of images per class for training\n",
    "  -vr VAL_RANGE VAL_RANGE, --val-range VAL_RANGE VAL_RANGE\n",
    "                        range of images per class for validation\n",
    "```\n",
    "\n",
    "\n",
    "### Entrenamiento semi-supervisado con FixMatch sobre CIFAR  \n",
    "\n",
    "El script `fixmatch.py` permite la ejecución de un entrenamiento semi-supervisado sobre CIFAR10 o CIFAR100. Gran parte de los hiper parámetros de entrenamiento son ajustables, como también lo es la arquitectura del modelo WideResNet utilizar. Se muestran a continuación las opciones disponibles para ejecutar el script.\n",
    "\n",
    "```{bash}\n",
    "usage: fixmatch.py [-h] [-d {cifar10,cifar100}] [-e EPOCHS] [-bs BATCH_SIZE]\n",
    "                   [-md MODEL_DEPTH] [-mw MODEL_WIDTH] [-es EARLY_STOPPING]\n",
    "                   [-r RESULTS] [-tr TRAIN_RANGE TRAIN_RANGE]\n",
    "                   [-vr VAL_RANGE VAL_RANGE]\n",
    "                   [-ulr UNLABELED_RANGE UNLABELED_RANGE] [-tau TAU] [-mu MU]\n",
    "                   [--lambda-u LAMBDA_U] [-N N] [-M M]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -d {cifar10,cifar100}, --data {cifar10,cifar100}\n",
    "                        dataset for training\n",
    "  -e EPOCHS, --epochs EPOCHS\n",
    "                        number of epochs for training\n",
    "  -bs BATCH_SIZE, --batch-size BATCH_SIZE\n",
    "                        batch size for training\n",
    "  -md MODEL_DEPTH, --model-depth MODEL_DEPTH\n",
    "                        depth of Wide ResNet model\n",
    "  -mw MODEL_WIDTH, --model-width MODEL_WIDTH\n",
    "                        width of Wide ResNet model\n",
    "  -es EARLY_STOPPING, --early-stopping EARLY_STOPPING\n",
    "                        number of epochs for early stopping\n",
    "  -r RESULTS, --results RESULTS\n",
    "                        folder name for training results\n",
    "  -tr TRAIN_RANGE TRAIN_RANGE, --train-range TRAIN_RANGE TRAIN_RANGE\n",
    "                        range of images per class for training\n",
    "  -vr VAL_RANGE VAL_RANGE, --val-range VAL_RANGE VAL_RANGE\n",
    "                        range of images per class for validation\n",
    "  -ulr UNLABELED_RANGE UNLABELED_RANGE, --unlabeled-range UNLABELED_RANGE UNLABELED_RANGE\n",
    "                        range of images per class for unlabeled data\n",
    "  -tau TAU, --tau TAU   threshold for retaining a pseudo-label\n",
    "  -mu MU, --mu MU       multiplier of batch size for unlabeled data\n",
    "  --lambda-u LAMBDA_U   unsupervised loss multiplier lambda\n",
    "  -N N, --N N           number of transformations for RandAugment\n",
    "  -M M, --M M           magnitude of transformations in RandAugment\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c60e2e7b-8b01-43d1-bb49-bab4d510160f",
     "kernelId": ""
    },
    "id": "Q8ZqH9Z5AC7V"
   },
   "source": [
    "## Baseline sin Fixmatch utilizando todo el dataset\n",
    "\n",
    "Este experimento busca tener un baseline de comparación, para ello se entrena en primer lugar sobre todo el dataset de CIFAR10 en un esquema supervisado. De las 5000 imágenes por clases de CIFAR10, 1000 se ocupan para evaluar la red y las restantes 4000 se utilizan para entrenar. Los hiperparámetros a utilizar son:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f4ad10c6-160e-4ede-8972-4af5eb3226d1",
     "kernelId": ""
    },
    "id": "Iw8WFQosJU3u"
   },
   "outputs": [],
   "source": [
    "!python src/supervised.py -d cifar10 -e 100 -bs 512 -md 22 -mw 2 -es 15 -r baseline1 -tr 0 4000 -vr 4000 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline sin FixMatch utilizando porción restringida de entrenamiento\n",
    "En este experimento se entrena sobre parte reducida del dataset de entrenamiento, de forma de evidenciar las limitaciones de entrenar con pocos datos."
   ],
   "metadata": {
    "id": "73M7sTKAZVUW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python src/supervised.py -d cifar10 -e 300 -bs 256 -md 22 -mw 2 -es 15 -r baseline2 -tr 0 400 -vr 4000 5000"
   ],
   "metadata": {
    "id": "p3jVDmpNZmPa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cbd89895-eec1-4728-8d5f-2f5d76106b42",
     "kernelId": ""
    },
    "id": "JnDr23VhYvAC"
   },
   "source": [
    "## Fixmatch con RandAugment(N=2, M=9)\n",
    "\n",
    "En este experimento se entrena con fixmatch utilizando parte reducida del dataset de forma etiquetada y la totalidad del dataset de forma no etiquetada. El esquema de data augmentation fuerte es RandAugment con parámetros N=2 y M=9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "3eba8e5b-acae-41f9-a7df-28a49fb0026a",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "id": "3HFEoQWfYvAD"
   },
   "outputs": [],
   "source": [
    "!python src/fixmatch.py -d cifar10 -e 100 -bs 128 -md 22 -mw 2 -es 15 -r fixmatch1 -tr 0 400 -vr 4000 5000 -ulr 0 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixmatch con RandAugment(N=3, M=4)\n",
    "\n",
    "En este experimento se entrena con fixmatch utilizando parte reducida del dataset de forma etiquetada y la totalidad del dataset de forma no etiquetada. El esquema de data augmentation fuerte es RandAugment con parámetros N=3 y M=4."
   ],
   "metadata": {
    "id": "wi_7CvbYat8h"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "5e50eef8-5b1d-4629-8336-aa7e86f803ea",
     "kernelId": ""
    },
    "id": "3C6OS9biYvAD"
   },
   "outputs": [],
   "source": [
    "!python src/fixmatch.py -d cifar10 -e 100 -bs 128 -md 22 -mw 2 -es 15 -r fixmatch2 -tr 0 400 -vr 4000 5000 -ulr 0 4000 -N 3 -M 4"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline sin FixMatch utilizando porción restringida de entrenamiento\n",
    "En este experimento se entrena sobre parte reducida del dataset de entrenamiento, de forma de evidenciar las limitaciones de entrenar con pocos datos. En este caso se ha cambiado el modelo de WRN-22-2 a WRN-16-2."
   ],
   "metadata": {
    "id": "fg_Fm0kSa5NB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!python src/supervised.py -d cifar10 -e 300 -bs 256 -md 16 -mw 2 -es 15 -r baseline3 -tr 0 400 -vr 4000 5000"
   ],
   "metadata": {
    "id": "njFfFsHGbg7t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixmatch con RandAugment(N=2, M=9) WRN-16-2\n",
    "\n",
    "En este experimento se entrena con fixmatch utilizando parte reducida del dataset de forma etiquetada y la totalidad del dataset de forma no etiquetada. El esquema de data augmentation fuerte es RandAugment con parámetros N=2 y M=9. El modelo se ha cambiado de WRN-22-2 a WRN-16-2."
   ],
   "metadata": {
    "id": "N4vP-DAta5W5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "95cbe0cd-c773-4ca8-8c07-d5db98d12d62",
     "kernelId": ""
    },
    "id": "o0lH29K3YvAE"
   },
   "outputs": [],
   "source": [
    "!python src/fixmatch.py -d cifar10 -e 100 -bs 128 -md 16 -mw 2 -es 15 -r fixmatch3 -tr 0 400 -vr 4000 5000 -ulr 0 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline sin FixMatch utilizando porción restringida de entrenamiento\n",
    "En este experimento se entrena sobre parte reducida del dataset de entrenamiento, de forma de evidenciar las limitaciones de entrenar con pocos datos. En este caso, se utiliza CIFAR100"
   ],
   "metadata": {
    "id": "leHBYXHfbEns"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "29bf76d3-23b8-4af7-a2db-197078bed9f2",
     "kernelId": ""
    },
    "id": "V9_PJ3SXYvAF"
   },
   "outputs": [],
   "source": [
    "!python src/supervised.py -d cifar100 -e 300 -bs 512 -md 22 -mw 2 -es 15 -r baseline4 -tr 0 100 -vr 400 500"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixmatch con RandAugment(N=2, M=9) WRN-22-2 CIFAR100\n",
    "\n",
    "En este experimento se entrena con fixmatch utilizando parte reducida del dataset de forma etiquetada y la totalidad del dataset de forma no etiquetada. El esquema de data augmentation fuerte es RandAugment con parámetros N=2 y M=9. Se ha cambiado de CIFAR 10 a CIFAR 100."
   ],
   "metadata": {
    "id": "kM4rIOaWbMhJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5acd3989-fd74-436a-9c61-e932b819edc1",
     "kernelId": ""
    },
    "id": "WaVeOBqVYvAF"
   },
   "outputs": [],
   "source": [
    "!python src/fixmatch.py -d cifar100 -e 300 -bs 128 -md 22 -mw 2 -es 15 -r fixmatch4 -tr 0 100 -vr 400 500 -ulr 0 400"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resultados\n",
    "Todos los resultados, logs, modelos, etc. quedan almacenados en `FixMatchEL7008/runs`. Luego, se pueden descargar para ser procesados localmente, o en este mismo notebook de manera directa. Además se provee funcionalidad para generar los gráficos relevantes de cada entrenamiento y testeo. La siguiente celda ejemplifica el uso para uno de los entrenamientos, pero modificando la variable `folder` se puede utilizar para cualquiera de los resultados obtenidos."
   ],
   "metadata": {
    "id": "_k3_Ki-Pb1DT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5bfc3779-d887-45f1-88ba-40e6a7cf8063",
     "kernelId": ""
    },
    "id": "KDytVzI0YvAF"
   },
   "outputs": [],
   "source": [
    "from definitions import RUNS_DIR\n",
    "from src.train.summary.plotter import Plotter\n",
    "\n",
    "folder = 'fixmatch1'\n",
    "path = RUNS_DIR / folder\n",
    "num_classes = 100 if folder in ['baseline4', 'fixmatch4'] else 10\n",
    "plttr = Plotter(base_path=path, n_classes=num_classes)\n",
    "\n",
    "plttr.print_metadata(fixmatch='fixmatch' in folder)\n",
    "\n",
    "plttr.plot_loss(save=path / 'train_loss.png')\n",
    "plttr.plot_accu(save=path / 'train_accu.png')\n",
    "plttr.test_best(save=path / 'conf_matrix.png')\n",
    "\n",
    "if 'fixmatch' in folder:\n",
    "  plttr.plot_ssl_metrics(save=path / 'ssl_metrics.png')\n",
    "  plttr.plot_ssl_losses(save=path / 'ssl_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "y9BIAO-kc2zH"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "baseline.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}